<!DOCTYPE html>
<html lang="en">
<head>
  <title>Digital imaging techniques - part 1.3 processing and analysis</title>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="stylesheet" href="theme/screen-16x10.css">
</head>
<body class="shower list">

      <header class="caption">
      <h1>Presentation</h1>
      <p><a href="">Author</a></p>
      </header>
      
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Some important aspects in image processing and 2D image analysis</h2>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Some important aspects in image processing and 2D image analysis</h2>
    <ul data-view-type="live">
      <li data-view-type="live">Image Processing: image in -> image out</li>
      <li data-view-type="live">Image Analysis: image in -> measurements out</li>
      <li data-view-type="live">Image Understanding: image in ->high-level description out</li>
    </ul>
    <p data-view-type="course">Modern digital technology has made it possible to manipulate multi-dimensional signals. The goal of this manipulation can be divided into three categories:</p>
    <ul data-view-type="course">
      <li data-view-type="live">Image Processing image in -> image out</li>
      <li data-view-type="live">Image Analysis image in -> measurements out</li>
      <li data-view-type="live">Image Understanding image in -> high-level description out</li>
    </ul>
    <p data-view-type="course">We will first focus on some fundamental concepts of image processing. Then some introduction on image analysis will be given. Image understanding should be the aim of using different imaging techniques and requires a lot of expertise and experience. In this chapter we will restrict ourselves to two–dimensional (2D) image processing and 2D image analysis, although most of the concepts and techniques that are to be described can be extended easily to three dimensions (see Chapter on X-ray CT and OctopusAnalysis/Morpho+).</p>
    <p data-view-type="live"></p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing</h2>
    <p data-view-type="live">Image processing is used in a wide variety of applications, for two different purposes:</p>
    <ol data-view-type="live">
      <li data-view-type="live">improving the visual appearance of images to a human observer, including their printing and transmission.</li>
      <li data-view-type="live">preparing images for the measurement of the features and structures which they reveal.</li>
    </ol>
    <p data-view-type="course">Image processing is used in a wide variety of applications, for two different purposes:</p>
    <ol data-view-type="course">
      <li data-view-type="live">improving the visual appearance of images to a human observer, including their printing and transmission.</li>
      <li data-view-type="live">preparing images for the measurement of the features and structures which they reveal.</li>
    </ol>
    <p data-view-type="course">The techniques that are appropriate for each of these tasks are not always the same, but there is considerable overlap. We will briefly discuss some aspects of image processing. For more detail we can refer to the book of John Russ “The imaging processing handbook”.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing</h2>
    <p data-view-type="live">A first group of image processing operations:</p>
    <ul data-view-type="live">
      <li data-view-type="live">procedures applied to correct defects in acquired images (due to imperfect detectors, limitations of optics, inadequate or non-uniform illumination or an undesirable viewpoint).</li>
      <li data-view-type="live">are applied after image has been digitized and stored => are unable to deliver highest quality result that can be achieved by optimizing/correcting the acquisition process in the first place. (of course not always possible to obtain a perfect digital image in reality).</li>
    </ul>
    <p data-view-type="course">A first group of image processing operations are those procedures applied to correct some of the defects in acquired images that may be present due to imperfect detectors, limitations of the optics, inadequate or non-uniform illumination or an undesirable viewpoint. It is important to emphasize that these corrections are applied after the image has been digitized and stored and therefore are unable to deliver the highest quality result that can be achieved by optimizing or correcting the acquisition process in the first place. Of course, it is not always possible to obtain a perfect digital image in reality.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <iframe data-view-type="live" src="https://www.mentimeter.com/s/7c19b633f0c80af9fd7bdfbabb672945/7707310e22f4/edit" alt=""></iframe></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <ul data-view-type="live">
      <li data-view-type="live">digital images can be represented by: values from 0 (black) to 255 (white), producing one byte (8 bit) values, or for colour images one byte each for red, green, and blue.</li>
      <li data-view-type="live">If camera has more precision, the values may have more bits of precision = full dynamic range of the camera</li>
      <li data-view-type="live">No reason that the actual image data must cover the full range.</li>
    </ul>
    <p data-view-type="course"><strong>Contrast expansion</strong></p>
    <p data-view-type="course">We have already seen that the typical digitization process for images produces values from 0 (black) to 255 (white), producing one byte (8 bit) values, or for colour images one byte each for red, green, and blue. If the camera and digitizer have more precision, the values may have 10, 12, or even more bits of precision and typically occupy two bytes each. But while this is the full dynamic range available to the output of the camera sensors, there is no reason that the actual image data must cover the full range.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <ul data-view-type="live">
      <li data-view-type="live">In many situations: recorded image has a much smaller range of brightness values, which may either lie in middle of the range (intermediate gray values) or toward either the bright or dark end of the range.</li>
    </ul>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <p data-view-type="live">If range of variation in brightness of the image is much smaller than dynamic range of the camera and digitizer, then the actual range of numbers is much less than the full range of 0 through 255, as seen below</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding5.png');"><img data-view-type="live" 
              data-id="215"
              src="assets/Afbeelding5.png"
              alt="grey value image with corresponding histogram, original"/></div>
              <figcaption><a href="assets/Afbeelding5.png">
                                
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">If the inherent range of variation in brightness of the image is much smaller than the dynamic range of the camera, subsequent electronics, and digitizer, then the actual range of numbers is much less than the full range of 0 through 255. The figure on this slide shows such an example.</p>
    <p data-view-type="course">The specimen in the figure on this slide is a thin section through tissue, shown in a bright field microscope. Illumination in the microscope and light staining of the section produce very little total contrast. The narrow peak and empty regions at the ends of the histogram indicate that many of the possible brightness levels are not used.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <p data-view-type="live">linear expansion of brightness range</p>
    <p data-view-type="live">=> a full range of black to white values but gaps in histogram</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding6.png');"><img data-view-type="live" 
              data-id="206"
              src="assets/Afbeelding6.png"
              alt="grey value image with corresponding histogram, linear expansion"/></div>
              <figcaption><a href="assets/Afbeelding6.png">
                                
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">Visibility of the structures present can be improved by stretching the contrast so that the values of pixels are reassigned to cover the entire available range (see figure on slide).</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <p data-view-type="live">mapping is linear and one-to-one</p>
    <p data-view-type="live">=> darkest pixels in original image are assigned to black, lightest pixels are assigned to white, and intermediate gray values in original image are given new values (linearly interpolated between black and white)</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding6.png');"><img data-view-type="live" 
              data-id="206"
              src="assets/Afbeelding6.png"
              alt="grey value image with corresponding histogram, linear expansion"/></div>
              <figcaption><a href="assets/Afbeelding6.png">
                                
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">The mapping is linear and one-to-one. This means that the darkest pixels in the original image are assigned to black, the lightest pixels are assigned to white, and intermediate gray values in the original image are given new values which are linearly interpolated between black and white.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <p data-view-type="live">All of the pixels which have the same gray value in the original image are assigned the same new gray value in the resulting image.</p>
    <p data-view-type="live">Due to reassignment of gray values: ↑ visual contrast for the pixels present, but no increase in ability to discriminate subtle variations in gray scale that are not recorded in original image.</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding6a.png');"><img data-view-type="live" 
              data-id="151"
              src="assets/Afbeelding6a.png"
              alt="grey value image with corresponding histogram, original and linear expansion"/></div>
              <figcaption><a href="assets/Afbeelding6a.png">
                                fig. 17
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">All of the pixels which have one gray value in the original image are assigned the same new gray value in the resulting image. This histogram plotted with the image in the figure now shows counts of pixels for gray levels that are spread out across the available brightness scale. However, many of the gray values still show zero counts in the histogram, indicating that no pixels have those values. The reassignment of gray values has increased the visual contrast for the pixels present, but has not increased the ability to discriminate subtle variations in gray scale that are not recorded in the original image. It has also magnified the brightness differences associated with noise in the original image.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: contrast expansion</h2>
    <p data-view-type="live">Acquiring image with optimum illumination and camera exposure</p>
    <p data-view-type="live">=> produces a visually similar result as after contrast expansion but without gaps in the histogram.</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding6b.png');"><img data-view-type="live" 
              data-id="181"
              src="assets/Afbeelding6b.png"
              alt="grey value image with corresponding histogram, better acquisition"/></div>
              <figcaption><a href="assets/Afbeelding6b.png">
                                
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">The top figure on this slide shows the same field of view acquired utilizing the entire range of the camera and digitizer. This may require adjusting the illumination, camera gain, or exposure time, etc., and may require trial and error in the settings, which are simplified if a live histogram can be shown. The mean brightness of various structures is similar to that shown in the previous slides. However, all of the 256 possible gray values are now present in the image, and small variations in sample density can now be distinguished</p>
    <p data-view-type="course">However, it is often not practical to adjust the illumination, camera gain, etc., to exactly fill the available pixel depth (the number of gray levels that can be digitized or stored). Furthermore, increasing the brightness range too much can cause pixel values at the dark and/or light ends of the range to exceed the digitization and storage capacity and to be clipped to the limiting values, which also causes loss of information. Figure 18 shows an example, a night scene in which the brightness scale of the face of the building is good but bright lights are brighter than the white limit of the camera and consequently are clipped to the maximum value of 255, while the dark areas around the building are underexposed and clipped to zero (black), losing any detail that might have been present.</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/k1.PNG');"><img data-view-type="live" 
              data-id="201"
              src="assets/k1.PNG"
              alt="FIGURE 18: A night scene in which the bright lights are clipped to white and the shadows are clipped to black. Information lost due to clipping cannot be recovered."/></div>
              <figcaption><a href="assets/k1.PNG">
                                FIGURE 18: A night scene in which the bright lights are clipped to white and the shadows are clipped to black. Information
      						lost due to clipping cannot be recovered.
                            </a></figcaption></div></figure>
    </div></div>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: what about noisy images?</h2>
    <p data-view-type="live">linear expansion of contrast often accompanied by increased visibility for noise that may be present.</p>
    <p data-view-type="live">Noise: important defect in images that can take many different forms and arise from various sources.</p>
    <p data-view-type="course"><strong>Noisy images</strong></p>
    <p data-view-type="course">The linear expansion of contrast shown in the examples above is often accompanied by an increased visibility for noise (random fluctuations in pixel values) that may be present. Noise is an important defect in images that can take many different forms and arise from various sources.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">What is the most important raison of noise in images?</h2>
    <ol data-view-type="live">
      <li data-view-type="live">A bad microscope configuration</li>
      <li data-view-type="live">The used illumination time</li>
      <li data-view-type="live">The used camera</li>
    </ol>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">How can we reduce noise in images?</h2>
    <ol data-view-type="live">
      <li data-view-type="live">By averaging the number of frames</li>
      <li data-view-type="live">By using longer exposure times</li>
      <li data-view-type="live">By image processing using filters</li>
      <li data-view-type="live">Other method?</li>
    </ol>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: what about noisy images?</h2>
    <p data-view-type="live">It is possible to improve in image quality (technically, signal to-noise ratio) by averaging a number of frames.</p>
    <p data-view-type="course">It is possible to improve in image quality (technically, signal to-noise ratio) by averaging a number of frames.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
    <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding7.png');"><img data-view-type="live" 
              data-id="204"
              src="assets/Afbeelding7.png"
              alt="Kim et al. LED and CMOS image sensor based hemoglobin concentration measurement technique, Sensors and Actuators B: Chemical, 157(1), 2011, Pages 103-109."/></div>
              <figcaption><a href="assets/Afbeelding7.png">
                            Kim et al. LED and CMOS image sensor based hemoglobin concentration measurement technique, Sensors and Actuators B: Chemical,
      						157(1), 2011, Pages 103-109.
      					
                        </a></figcaption></div></figure>
  </div></div></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: what about noisy images?</h2>
    <p data-view-type="live">Sources of noise:</p>
    <ul data-view-type="live">
      <li data-view-type="live">counting statistics in the image detector due to a small number of incident particles (photons, electrons, etc.).</li>
      <li data-view-type="live">due to instability in the light source or detector during the time required to scan or digitize an image.</li>
    </ul>
    <p data-view-type="course">However, one unavoidable source of noise is counting statistics in the image detector due to a small number of incident particles (photons, electrons, etc.). Noisy images may also occur due to instability in the light source or detector during the time required to scan or digitize an image. The pattern of this noise may be different from the essentially Gaussian noise due to counting statistics, but it still shows up as a variation in brightness in uniform regions of the scene.</p>
    <p data-view-type="course">When the noise has a characteristic that is not random in time and does not exhibit “normal” statistical behaviour, it is more difficult to place meaningful numeric descriptors on the amount of noise. However, many of the same techniques can be used, usually with somewhat less efficacy, to reduce the noise.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <p data-view-type="live">Noise reduction by the use of frame averaging versus “staring” mode in camera.</p>
    <ul data-view-type="live">
      <li data-view-type="live">Frame averaging: combining many sequential readouts from a camera</li>
      <li data-view-type="live">Staring mode: using a camera that can integrate the charge internally before it is read out. ( often used in astronomy, fluorescence microscopy, and other applications with very faint images); the camera is open to the incident light.</li>
    </ul>
    <p data-view-type="course">Assuming that an image represents the best quality that can practically be obtained, we will focus on ways to suppress noise to improve the ability to visualize and demarcate for measurement the features which are present. The underlying assumptions in all of these methods are that the pixels in the image are much smaller than any of the important details, and that for most of the pixels present, their neighbours represent the same structure. Various averaging and comparison methods can be applied based on these assumptions.</p>
    <p data-view-type="course">There are important differences between noise reduction by the use of frame averaging to combine many sequential readouts from a camera and the use of a camera that can integrate the charge internally before it is read out. The latter mode is employed in astronomy, fluorescence microscopy, and other applications with very faint images and is sometimes called “staring” mode since the camera is open to the incident light.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding7b.png');"><img data-view-type="live" 
              data-id="195"
              src="assets/Afbeelding7b.png"
              alt="SEM images of a scratched metal surface"/></div>
              <figcaption><a href="assets/Afbeelding7b.png">
                                SEM images of a scratched metal surface: (a) 1 second scan and histogram;(b) 20 second scan and histogram.
                            </a></figcaption></div></figure>
    </div></div>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <ul data-view-type="live">
      <li data-view-type="live">The fast scan image: collects few electrons per pixel; has a high random noise level that obscures details in the image.</li>
      <li data-view-type="live">Slowing the scan rate down from 1 s to 20 s increases amount of signal and reduces the noise.</li>
      <li data-view-type="live">The histograms show that the variation of brightness within the uniform region is reduced (the peak is narrowed), which is why the visibility of detail is improved.</li>
    </ul>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/Afbeelding7b.png');"><img data-view-type="live" 
              data-id="195"
              src="assets/Afbeelding7b.png"
              alt="SEM images of a scratched metal surface"/></div>
              <figcaption><a href="assets/Afbeelding7b.png">
                                (Fig. 19)
                            </a></figcaption></div></figure>
    </div></div>
    <p data-view-type="course">Figure 19 shows a comparison of two SEM images taken at different scan rates. The fast scan image collects few electrons per pixel and so has a high random noise level that obscures details in the image. Slowing the scan rate down from 1 second to 20 seconds increases the amount of signal and reduces the noise. The histograms show that the variation of brightness within the uniform region is reduced (the peak is narrowed), which is why the visibility of detail is improved.</p>
    <p data-view-type="course">Many digital cameras allow setting an equivalent ASA rating, corresponding to film sensitivity. The higher the ASA rating the shorter the exposure and/or the smaller the aperture used to capture the image. This requires a higher gain in the amplification of the signal, producing a higher level of random noise. Figure 20 shows the reduction of noise and improvement in image quality with longer exposure time (achieved by reducing the ASA setting on the camera from 1600 to 100). The noisy image in Figure 20a is also the starting point for various noise reduction methods shown below.</p>
    <div class="ows-image-container"><div class="ows-image-container-wrapper" data-image-type="illustrative_image">
      <figure><div class="ows-figure-wrapper"><div class="ows-figure-image-wrapper" style="background-image: url('assets/k2.PNG');"><img data-view-type="live" 
              data-id="210"
              src="assets/k2.PNG"
              alt="Figure 20: Noise reduction by collecting more signal: (a) image recorded at ASA 1600 setting,
      					 1/800 second exposure; (b) same image recorded at ASA 100 setting, 1/50 second exposure. "/></div>
              <figcaption><a href="assets/k2.PNG">
                                Figure 20: Noise reduction by collecting more signal: (a) image recorded at ASA 1600 setting, 1/800 second exposure; (b)
      						same image recorded at ASA 100 setting, 1/50 second exposure.
                            </a></figcaption></div></figure>
    </div></div>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <p data-view-type="live">Besides frame averiging and longer exposure times</p>
    <p data-view-type="live">also image processing possible!</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <p data-view-type="live">We assume: the image represents the best quality that can be obtained. Underlying assumptions in all of the next methods are:</p>
    <ul data-view-type="live">
      <li data-view-type="live">the pixels are much smaller than any of the important details</li>
      <li data-view-type="live">for most of the pixels present, their neighbours represent the same structure.</li>
    </ul>
    <p data-view-type="live">based on these assumptions, various averaging and comparison methods can be applied</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <p data-view-type="live"><strong>neighbourhood averaging: </strong>simplest form of spatial averaging: to add together the pixel brightness values in each small region of the image, divide by the number of pixels in the neighbourhood, and use the resulting value to construct a new image.</p>
    <p data-view-type="course"><strong>Neighbourhood averaging</strong></p>
    <p data-view-type="course">The simplest form of spatial averaging is to add together the pixel brightness values in each small region of the image, divide by the number of pixels in the neighbourhood, and use the resulting value to construct a new image.</p>
  </section></div>
    
        <div class="slide" data-level="0">
  <section data-view-type="live">
    <h2 data-view-type="live">Image processing: noisy images</h2>
    <p data-view-type="live"><strong>neighbourhood averaging:</strong></p>
  </section></div>
    
      <div class="progress"></div>
    
  <script src="https://cdnjs.cloudflare.com/ajax/libs/shower-core/2.1.0/shower.min.js"></script>
</body>
</html>
